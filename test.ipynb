{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = '../SynologyDrive/data/data_v1.0.0/data_v1_all_sequence_ag.json'\n",
    "data = json.load(open(data, 'r'))\n",
    "pdb_id = list(data.keys())\n",
    "ds = list(data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenization import Tokenizer\n",
    "\n",
    "encoder_vocab = ['PAD', 'SOS', 'EOS', 'A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
    "decoder_vocab = encoder_vocab + ['SEP']\n",
    "\n",
    "# Make a dictionary\n",
    "encoder_vocab = {encoder_vocab[i]: i for i in range(len(encoder_vocab))}\n",
    "decoder_vocab = {decoder_vocab[i]: i for i in range(len(decoder_vocab))}\n",
    "\n",
    "enc_tokenizer = Tokenizer(encoder_vocab, pre_tokenizer=' ')\n",
    "dec_tokenizer = Tokenizer(decoder_vocab, pre_tokenizer=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P S F Y T H T I V N I T I D L G M K R S G Y G Q P I A S T L S N I T L P M Q D N N T D V Y C I R S D Q F S V Y V H S T C K S S L W D N I F K R N C T D V L D A T A V I K T G T C P F S F D K L N N Y L T F N K F C L S L S P V G A N C K F D V A A R T R T N E Q V V R S L Y V I Y E E G D N I V L V P R'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]['pdb_sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('P S F Y T H T I V N I T I D L G M K R S G Y G Q P I A S T L S N I T L P M Q D N N T D V Y C I R S D Q F S V Y V H S T C K S S L W D N I F K R N C T D V L D A T A V I K T G T C P F S F D K L N N Y L T F N K F C L S L S P V G A N C K F D V A A R T R T N E Q V V R S L Y V I Y E E G D N I V L V P R',\n",
       " 'P S F Y T H T I V N I T I D L G M K R S G Y G Q P I A S T L S N I T L P M Q D N N T D V Y C I R S D Q F S V Y V H S T C K S S L W D N I F K R N C T D V L D A T A V I K T G T C P F S F D K L N N Y L T F N K F C L S L S P V G A N C K F D V A A R T R T N E Q V V R S L Y V I Y E E G D N I V L V P R ')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]['pdb_sequence'], enc_tokenizer.decode(enc_tokenizer.encode(ds[0]['pdb_sequence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[17, 18, 16, 21, 19, 11, 19, 12, 22,  5, 12, 19, 12,  6, 13, 10, 15, 14,\n",
      "          4, 18, 10, 21, 10,  8, 17, 12,  3, 18, 19, 13, 18,  5, 12, 19, 13, 17,\n",
      "         15,  8,  6,  5,  5, 19,  6, 22, 21,  7, 12,  4, 18,  6,  8, 16, 18, 22,\n",
      "         21, 22, 11, 18, 19,  7, 14, 18, 18, 13, 20,  6,  5, 12, 16, 14,  4,  5,\n",
      "          7, 19,  6, 22, 13,  6,  3, 19,  3, 22, 12, 14, 19, 10, 19,  7, 17, 16,\n",
      "         18, 16,  6, 14, 13,  5,  5, 21, 13, 19, 16,  5, 14, 16,  7, 13, 18, 13,\n",
      "         18, 17, 22, 10,  3,  5,  7, 14, 16,  6, 22,  3,  3,  4, 19,  4, 19,  5,\n",
      "          9,  8, 22, 22,  4, 18, 13, 21, 22, 12, 21,  9,  9, 10,  6,  5, 12, 22,\n",
      "         13, 22, 17,  4]])\n",
      "torch.Size([1, 148])\n"
     ]
    }
   ],
   "source": [
    "from model import PositionalEncoding, InputEmbeddings\n",
    "import torch\n",
    "\n",
    "x = enc_tokenizer.encode(ds[0]['pdb_sequence'])\n",
    "x = enc_tokenizer.to_tensor(x, dtype=torch.long)\n",
    "\n",
    "src_embed = InputEmbeddings(d_model=148, vocab_size=23) # (batch x seq_len) --> (batch x seq_len x d_model)\n",
    "src_pe = PositionalEncoding(d_model=148, seq_len=1000, dropout=0.1) # (batch x seq_len x d_model) --> (batch x seq_len x d_model)\n",
    "\n",
    "x = src_embed(x)\n",
    "x = src_pe(x)\n",
    "x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
